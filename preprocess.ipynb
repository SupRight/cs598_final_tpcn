{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28e80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Get busy living or get busy dying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951ca937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox\n",
      "[('The', 'DT', 'DET'), ('quick', 'JJ', 'ADJ'), ('brown', 'JJ', 'ADJ'), ('fox', 'NN', 'NOUN')]\n",
      "the lazy brown dog\n",
      "[('the', 'DT', 'DET'), ('lazy', 'JJ', 'ADJ'), ('brown', 'JJ', 'ADJ'), ('dog', 'NN', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy brown dog\"\n",
    "doc = nlp(text)\n",
    "for nc in doc.noun_chunks:\n",
    "    print(nc)  \n",
    "    print([(token.text, token.tag_, token.pos_) for token in nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCONJ: and, or (coordinating conjunctions)\n",
    "SCONJ: because, while, although  (subordinating conjunctions)\n",
    "DET: a, an, the, this, these, those, that, my,  your,  his,  her, any,  many, few, some, no... (determiners ('articles'))\n",
    "AUX: am,  is,  are,  was,  were,  has,  have,  had,  been, (auxiliary verbs) \n",
    "MOD: can,  could,  may,  might,  must,  should (modal verbs) \n",
    "VERB: see,  sees,  saw,  look,  looks,  looked,  sleep,  sleeps,  slept,  play,  plays, played,  .... (infinitive (to sleep), present tense  (he sleeps) and past tense (he slept))\n",
    "PRESPART: seeing,  looking,  sleeping,  playing,  ...  (present participle)\n",
    "PASTPART: seen,  looked,  slept,  played,  ...  (past participle: has seen)\n",
    "PRON: I,  you,  he,  she,  it,  we,  they,  me,  him,  her,  us,  them,  that,  this, none, any,  (pronouns, act as NPs) \n",
    "WPRON: what,  why,  where, who, whom, whose (wh-pronouns, used in questions: what do you like)\n",
    "WDET: which,  whose (wh-determiners, used with a noun: which dish did you order?)\n",
    "PROPN: Urbana,  Illinois,  Beijing ,  Tom,  Kim,  Google,  IBM,  (any proper noun/name)\n",
    "NOUN: chocolate,  book,  books,  ...  (any noun, singular/plural)\n",
    "ADP: to,  of,  with,  in,  on,  under,  above,  ... (prepositions, used in a PP where they are followed by a noun: in China)\n",
    "PART: up,  down,  in,  out (participles, go with a verb, and are used without a noun: I look up \n",
    "POS: 's,  '  (possessive 's,)\n",
    "DO: do, does, did    (used e.g. for yes-no questions, or for negated VPs)      NOT: not, n't     (negation) TO: to  (for infinitival verb phrases: to be or not to be)\n",
    "COMP: that, whether, who, which, what, that    (complementizer, followed by a sentence or relative clause)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb58ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"903735b363fb4eae9d7739812f14b269-0\" class=\"displacy\" width=\"1800\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,89.5 1620.0,89.5 1620.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-903735b363fb4eae9d7739812f14b269-0-8\" stroke-width=\"2px\" d=\"M945,352.0 C945,2.0 1625.0,2.0 1625.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-903735b363fb4eae9d7739812f14b269-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,354.0 L1633.0,342.0 1617.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "displacy.render(doc,jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780955e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aleczhao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aleczhao/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Illegal chunk pattern: {",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.9/site-packages/nltk/chunk/regexp.py:392\u001b[0m, in \u001b[0;36mRegexpChunkRule.fromstring\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllegal chunk pattern: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m rule)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, re\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: Illegal chunk pattern: {",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m tagged \u001b[38;5;241m=\u001b[39m pos_tag(word_tokenize(sample_text))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Extract all parts of speech from any text\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m chunker \u001b[38;5;241m=\u001b[39m \u001b[43mRegexpParser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m                       NP: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m<DT>?<JJ>*<NN>}    #To extract Noun Phrases\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m                       P: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m<IN>}               #To extract Prepositions\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m                       V: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m<V.*>}              #To extract Verbs\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m                       PP: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m \u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m<p> <NP>}          #To extract Prepositional Phrases\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m                       VP: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m<V> <NP|PP>*}      #To extract Verb Phrases\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m                       \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print all parts of speech in above sentence\u001b[39;00m\n\u001b[1;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m chunker\u001b[38;5;241m.\u001b[39mparse(tagged)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.9/site-packages/nltk/chunk/regexp.py:1198\u001b[0m, in \u001b[0;36mRegexpParser.__init__\u001b[0;34m(self, grammar, root_label, loop, trace)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop \u001b[38;5;241m=\u001b[39m loop\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(grammar, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1198\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_grammar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;66;03m# Make sur the grammar looks like it has the right type:\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m     type_err \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected string or list of RegexpChunkParsers \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the grammar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1203\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.9/site-packages/nltk/chunk/regexp.py:1238\u001b[0m, in \u001b[0;36mRegexpParser._read_grammar\u001b[0;34m(self, grammar, root_label, trace)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;66;03m# Add the rule\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     rules\u001b[38;5;241m.\u001b[39mappend(\u001b[43mRegexpChunkRule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;66;03m# Record the final stage\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_stage(rules, lhs, root_label, trace)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.9/site-packages/nltk/chunk/regexp.py:394\u001b[0m, in \u001b[0;36mRegexpChunkRule.fromstring\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllegal chunk pattern: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m rule)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, re\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIllegal chunk pattern: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m rule) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Illegal chunk pattern: {"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "  \n",
    "# Example text\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "  \n",
    "# Find all parts of speech in above sentence\n",
    "tagged = pos_tag(word_tokenize(sample_text))\n",
    "  \n",
    "#Extract all parts of speech from any text\n",
    "chunker = RegexpParser(\"\"\"\n",
    "                       NP: {<DT>?<JJ>*<NN>}    #To extract Noun Phrases\n",
    "                       P: {<IN>}               #To extract Prepositions\n",
    "                       V: {<V.*>}              #To extract Verbs\n",
    "                       PP: {\n",
    " \n",
    "<p> <NP>}          #To extract Prepositional Phrases\n",
    "                       VP: {<V> <NP|PP>*}      #To extract Verb Phrases\n",
    "                       \"\"\")\n",
    " \n",
    "# Print all parts of speech in above sentence\n",
    "output = chunker.parse(tagged)\n",
    "print(\"After Extracting\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c7e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
